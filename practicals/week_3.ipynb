{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "The `pandas` library allows the user several data structures for different data manipulation tasks:\n",
    "1. Data storage through its `Series` and `DataFrame` data structures.\n",
    "2. Data filtering using multiple methods from the package.\n",
    "3. Reading data from many different file formats such as `csv`, `txt`, `xlsx`, ...\n",
    "\n",
    "Below we provide a brief overview of the `pandas` functionalities needed for these exercises. The complete documentation can be found on the [`pandas` website](https://pandas.pydata.org/).\n",
    "\n",
    "## Pandas data structures\n",
    "\n",
    "### Series\n",
    "The Pandas Series data structure is similar to a one-dimensional array. It can store any type of data. The values are mutable but the size not.\n",
    "\n",
    "To create `Series`, we call the `pd.Series()` method and pass an array. A `Series` may also be created from a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1      10\n",
      "2     100\n",
      "3    1000\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "0          PSV\n",
      "1         Ajax\n",
      "2    Feyenoord\n",
      "3       Twente\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "first_series = pd.Series([1,10,100,1000])\n",
    "\n",
    "print(first_series)\n",
    "\n",
    "teams = np.array(['PSV','Ajax','Feyenoord','Twente'])\n",
    "second_series = pd.Series(teams)\n",
    "\n",
    "print('\\n')\n",
    "print(second_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "One can think of a `DataFrame` as a table with rows and columns (2D structure). The columns can be of a different type (as opposed to `numpy` arrays) and the size of the `DataFrame` is mutable.\n",
    "\n",
    "To create `DataFrame`, we call the `pd.DataFrame()` method and we can create it from scratch or we can convert a numpy array or a list into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From scratch: \n",
      "    Position       Team  GF  GA  Points\n",
      "0         1        PSV  80  30      79\n",
      "1         2       Ajax  75  25      78\n",
      "2         3  Feyenoord  75  40      70\n",
      "3         4     Twente  70  60      66 \n",
      "\n",
      "From list: \n",
      "   Position       Team  GF  GA Points\n",
      "0        1        PSV  80  30     79\n",
      "1        2       Ajax  75  25     78\n",
      "2        3  Feyenoord  75  40     70\n",
      "3        4     Twente  70  60     66 \n",
      "\n",
      "From numpy array: \n",
      "   Position       Team  GF  GA Points\n",
      "0        1        PSV  80  30     79\n",
      "1        2       Ajax  75  25     78\n",
      "2        3  Feyenoord  75  40     70\n",
      "3        4     Twente  70  60     66 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame from scratch\n",
    "first_dataframe = pd.DataFrame({\n",
    "    \"Position\": [1, 2, 3, 4],\n",
    "    \"Team\": ['PSV','Ajax','Feyenoord','Twente'],\n",
    "    \"GF\": [80, 75, 75, 70],\n",
    "    \"GA\": [30, 25, 40, 60],\n",
    "    \"Points\": [79, 78, 70, 66]\n",
    "})\n",
    "\n",
    "print(\"From scratch: \\n {} \\n\".format(first_dataframe))\n",
    "\n",
    "# DataFrme from a list\n",
    "data = [[1, 2, 3, 4], ['PSV','Ajax','Feyenoord','Twente'], \n",
    "        [80, 75, 75, 70], [30, 25, 40, 60], [79, 78, 70, 66]]\n",
    "columns = [\"Position\", \"Team\", \"GF\", \"GA\", \"Points\"]\n",
    "\n",
    "second_dataframe = pd.DataFrame(data, index=columns)\n",
    "\n",
    "print(\"From list: \\n {} \\n\".format(second_dataframe.T)) # the '.T' operator is explained later on\n",
    "\n",
    "# DataFrame from numpy array\n",
    "data = np.array([[1, 2, 3, 4], ['PSV','Ajax','Feyenoord','Twente'], \n",
    "                 [80, 75, 75, 70], [30, 25, 40, 60], [79, 78, 70, 66]])\n",
    "columns = [\"Position\", \"Team\", \"GF\", \"GA\", \"Points\"]\n",
    "\n",
    "third_dataframe = pd.DataFrame(data.T, columns=columns)\n",
    "\n",
    "print(\"From numpy array: \\n {} \\n\".format(third_dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame attributes\n",
    "This section gives a quick overview of some of the `pandas.DataFrame` attributes such as `T`, `index`, `columns`, `iloc`, `loc`, `shape` and `values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0     1          2       3\n",
      "Position    1     2          3       4\n",
      "Team      PSV  Ajax  Feyenoord  Twente\n",
      "GF         80    75         75      70\n",
      "GA         30    25         40      60\n",
      "Points     79    78         70      66\n"
     ]
    }
   ],
   "source": [
    "# transpose the index and columns\n",
    "print(third_dataframe.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4, step=1)\n"
     ]
    }
   ],
   "source": [
    "# index makes reference to the row labels\n",
    "print(third_dataframe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Position', 'Team', 'GF', 'GA', 'Points'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# columns makes reference to the column labels\n",
    "print(third_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          PSV\n",
      "1         Ajax\n",
      "2    Feyenoord\n",
      "3       Twente\n",
      "Name: Team, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# iloc allows to access the index by integer-location (e.g. all team names, which are in the second columm)\n",
    "print(third_dataframe.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSV\n"
     ]
    }
   ],
   "source": [
    "# loc allows to access the index by label(s)-location (e.g. all team names, which are in the \"Team\" columm)\n",
    "print(third_dataframe.loc[0, 'Team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "# shape returns a tuple with the DataFrame dimension, similar to numpy\n",
    "print(third_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' 'PSV' '80' '30' '79']\n",
      " ['2' 'Ajax' '75' '25' '78']\n",
      " ['3' 'Feyenoord' '75' '40' '70']\n",
      " ['4' 'Twente' '70' '60' '66']]\n"
     ]
    }
   ],
   "source": [
    "# values return a Numpy representation of the DataFrame data\n",
    "print(third_dataframe.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame methods\n",
    "This section gives a quick overview of some of the `pandas.DataFrame` methods such as `head`, `describe`, `concat`, `groupby`,`rename`, `filter`, `drop` and `isna`. To import data from CSV or MS Excel files, we can make use of `read_csv` and `read_excel`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Position       Team  GF  GA Points\n",
      "0        1        PSV  80  30     79\n",
      "1        2       Ajax  75  25     78\n",
      "2        3  Feyenoord  75  40     70\n",
      "3        4     Twente  70  60     66\n"
     ]
    }
   ],
   "source": [
    "# print the first few rows in your dataset with head()\n",
    "print(third_dataframe.head()) # In this case, it is not very useful because we don't have thousands of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Position    Team  GF  GA Points\n",
      "count         4       4   4   4      4\n",
      "unique        4       4   3   4      4\n",
      "top           2  Twente  75  25     78\n",
      "freq          1       1   2   1      1\n"
     ]
    }
   ],
   "source": [
    "# get the summary statistics of the DataFrame with describe()\n",
    "print(third_dataframe.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Position  Team  GF  GA Points\n",
      "0        1   PSV  80  30     79\n",
      "1        2  Ajax  75  25     78\n",
      "\n",
      "\n",
      "  Position       Team  GF  GA Points\n",
      "2        3  Feyenoord  75  40     70\n",
      "3        4     Twente  70  60     66\n",
      "\n",
      "\n",
      "  Position       Team  GF  GA Points\n",
      "0        1        PSV  80  30     79\n",
      "1        2       Ajax  75  25     78\n",
      "2        3  Feyenoord  75  40     70\n",
      "3        4     Twente  70  60     66\n"
     ]
    }
   ],
   "source": [
    "# concatenate (join) DataFrame objects using concat()\n",
    "\n",
    "# first, we will split the above DataFrame in two different ones\n",
    "df_a = third_dataframe.loc[[0,1],:]\n",
    "df_b = third_dataframe.loc[[2,3],:]\n",
    "\n",
    "print(df_a)\n",
    "print('\\n')\n",
    "\n",
    "print(df_b)\n",
    "print('\\n')\n",
    "\n",
    "# now, we concatenate both datasets\n",
    "df = pd.concat([df_a, df_b])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Position       Team  GF  GA Points\n",
      "1        2       Ajax  75  25     78\n",
      "2        3  Feyenoord  75  40     70\n"
     ]
    }
   ],
   "source": [
    "# group the data by certain variable via groupby()\n",
    "# here, we have grouped the data by goals for, which in this case is 75\n",
    "\n",
    "group = df.groupby('GF')\n",
    "\n",
    "print(group.get_group('75'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pos       Club  GF  GA Points\n",
      "0   1        PSV  80  30     79\n",
      "1   2       Ajax  75  25     78\n",
      "2   3  Feyenoord  75  40     70\n",
      "3   4     Twente  70  60     66\n"
     ]
    }
   ],
   "source": [
    "# rename() helps you change the column or index names\n",
    "print(df.rename(columns={'Position':'Pos','Team':'Club'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Team Points\n",
      "0        PSV     79\n",
      "1       Ajax     78\n",
      "2  Feyenoord     70\n",
      "3     Twente     66\n"
     ]
    }
   ],
   "source": [
    "# build a subset of rows or columns of your dataset according to labels via filter()\n",
    "# here, items refer to the variable names: 'Team' and 'Points'; to select columns, we specify axis=1\n",
    "print(df.filter(items=['Team', 'Points'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Position       Team Points\n",
      "0        1        PSV     79\n",
      "1        2       Ajax     78\n",
      "2        3  Feyenoord     70\n",
      "3        4     Twente     66\n"
     ]
    }
   ],
   "source": [
    "# dropping some labels\n",
    "print(df.drop(columns=['GF', 'GA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Position   Team     GF     GA  Points\n",
      "0     False  False  False  False   False\n",
      "1     False  False  False  False   False\n",
      "2     False  False  False  False   False\n",
      "3     False  False  False  False   False\n",
      "\n",
      "\n",
      "  Position       Team  GF  GA Points     W\n",
      "0        1        PSV  80  30     79   NaN\n",
      "1        2       Ajax  75  25     78  25.0\n",
      "2        3  Feyenoord  75  40     70  24.0\n",
      "3        4     Twente  70  60     66  19.0\n",
      "\n",
      "\n",
      "   Position   Team     GF     GA  Points      W\n",
      "0     False  False  False  False   False   True\n",
      "1     False  False  False  False   False  False\n",
      "2     False  False  False  False   False  False\n",
      "3     False  False  False  False   False  False\n"
     ]
    }
   ],
   "source": [
    "# search for NA (not available) entries in the DataFrame\n",
    "print(df.isna()) # No NA values\n",
    "print('\\n')\n",
    "\n",
    "# create a pandas Series with a NA value\n",
    "# the Series as W (winnin matches)\n",
    "tmp = pd.Series([np.NaN, 25, 24, 19],  name=\"W\")\n",
    "\n",
    "# concatenate the Series with the DataFrame\n",
    "df = pd.concat([df,tmp], axis = 1)\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# again, check for NA entries\n",
    "print(df.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this week exercises we will use a dataset from the Genomics of Drug Sensitivity in Cancer (GDSC) project (https://www.cancerrxgene.org/). In this study (['Iorio et al., Cell, 2016']()), 265 compounds were tested on 1001 cancer cell lines for which different types of -omics data (RNA expression, DNA methylation, Copy Number Alteration, DNA sequencing) are available. This is a valuable resource to look for biomarkers of drugs sensitivity in order to try to understand why cancer patients responds very differently to cancer drugs and find ways to assign the optimal treatment to each patient.\n",
    "\n",
    "For this exercise we will use a subset of the data, focusing the response to the drug YM155 (Sepantronium bromide) on four cancer types, for a total of 148 cancer cell lines.\n",
    "\n",
    "| ID          | Cancer type                      |\n",
    "|-------------|----------------------------------|\n",
    "|   COAD/READ | Colorectal adenocarcinoma        |\n",
    "|   NB        | Neuroblastoma                    |\n",
    "|   KIRC      | Kidney renal clear cell carcinoma|\n",
    "|   BRCA      | Breast carcinoma                 |\n",
    "\n",
    "We will use the RNA expression data (RMA normalised). Only genes with high variability across cell lines (variance > 5, resulting in 238 genes) have been kept.\n",
    "\n",
    "Drugs have been tested at different concentration, measuring each time the viability of the cells. Drug sensitivity is measured using the natural log of the fitted IC50 metric, which is defined as the half maximal inhibitory concentration. A lower IC50 corresponds to a more sensitive cell line because a lower amount of drug is sufficient to have a strong response, while a higher IC50 corresponds to a more resistant cell line because more drug is needed for killing the cells.\n",
    "\n",
    "Based on the IC50 metric, cells can be classified as sensitive or resistant. The classification is done by computing the $z$-score across all cell lines in the GDSC for each drug, and considering as sensitive the ones with $z$-score < 0 and resistant the ones with $z$-score > 0.\n",
    "\n",
    "The dataset is originally provided as 3 files ([original source](https://www.sciencedirect.com/science/article/pii/S0092867416307462?via%3Dihub)) :\n",
    "\n",
    "`GDSC_RNA_expression.csv`: gene expression matrix with the cell lines in the rows (148) and the genes in the columns (238).\n",
    "\n",
    "`GDSC_drug_response.csv`: vector with the cell lines response to the drug YM155 in terms of log(IC50) and as classification in sensitive or resistant.\n",
    "\n",
    "`GDSC_metadata.csv`: metadata for the 148 cell lines including name, COSMIC ID and tumor type (using the classification from ['The Cancer Genome Atlas TCGA'](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga))\n",
    "\n",
    "For convenience, we provide the data already curated.\n",
    "\n",
    "`RNA_expression_curated.csv`: [148 cell lines , 238 genes]\n",
    "\n",
    "`drug_response_curated.csv`: [148 cell lines , YM155 drug]\n",
    "\n",
    "The curated data cam be read as `pandas` `DataFrame`s in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gene_expression = pd.read_csv(\"./data/RNA_expression_curated.csv\", sep=',', header=0, index_col=0)\n",
    "drug_response = pd.read_csv(\"./data/drug_response_curated.csv\", sep=',', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `DataFrame`s directly as inputs to the the `sklearn` models. The advantage over using `numpy` arrays is that the variable are annotated, i.e. each input and output has a name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "The `scikit-learn` library provides the required tools for linear regression/classification and shrinkage, as well as for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the notation used for the hyperparameters in the `scikit-learn` library is different from the one used in the lecture. More specifically, in the lecture $\\alpha$ is the tunable parameter to select the compromise between Ridge and Lasso. Whereas, `scikit-learn` library refers to `alpha` as the tunable parameter $\\lambda$. Please check the documentation for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Selection of the hyperparameter\n",
    "\n",
    "Implement cross-validation (using `sklearn.grid_search.GridSearchCV`) to select the `alpha` hyperparameter of `sklearn.linear_model.Lasso`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11190080861555167, tolerance: 0.06576589191011237\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1098332341283638, tolerance: 0.06951238719101124\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10121291191875786, tolerance: 0.07175522764044945\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12178300066492656, tolerance: 0.07369247101123595\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12702217191814286, tolerance: 0.06951238719101124\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (test set): 5.519\n",
      "0.3727593720314938\n",
      "The selected features are: ['PRSS3' 'GAL' 'CDH17' 'ABCB1' 'FN1' 'RARRES3' 'DUSP6' 'CYR61' 'FABP1'\n",
      " 'CDX2' 'AKR1C3']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize (pseudo-) random number generator with a seed\n",
    "# for reproducibility of results\n",
    "np.random.seed(40)\n",
    "\n",
    "def do_gridsearch_alpha(X_train, y_train, X_test, y_test, alphas, crossvals=5, plot=True):\n",
    "    \"\"\"\n",
    "    given a train and a test dataset, fit and evaluate polynomial regression models with given degrees\n",
    "    \n",
    "    Parameters: \n",
    "        X_train: 2D (Datapoints x features) numpy array\n",
    "            the datapoints on which to train the models\n",
    "        y_train: 1D (Targets) numpy array\n",
    "            the targets on which to train the models\n",
    "        X_test: 2D (Datapoints x features) numpy array\n",
    "            the datapoints on which to test the models\n",
    "        y_test: 1D (Targets) numpy array\n",
    "            the targets on which to test the models\n",
    "        alphas: 1D numpy array\n",
    "             alpha candidates\n",
    "        crossvals: int\n",
    "            amount of cross-validation folds\n",
    "        plot: bool\n",
    "            True for plotting the MSE scores, False for surpressing the plots\n",
    "    \n",
    "    returns: \n",
    "        a GridSearchCV object, containing the fitted models for every degree polynomial\n",
    "    \"\"\"\n",
    "    # Define the functions for polynomial features and linear regression\n",
    "    Lassoreg = Lasso(max_iter=10000)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Define the pipeline, containing the polynomial transformation and the subsequent linear regression\n",
    "    model = Pipeline([\n",
    "                     (\"scaler\", scaler),\n",
    "                     (\"lasso\", Lassoreg)\n",
    "                    ])\n",
    "\n",
    "    # Define the hyperparameters for the Grid Search\n",
    "    params = {'lasso__alpha': alphas}\n",
    "\n",
    "    # Define a custom scoring system to evaluate the mean squared error (lower is better)\n",
    "    mse = make_scorer(mean_squared_error,greater_is_better=False)\n",
    "\n",
    "    # Define the Grid Search method\n",
    "    gridsearch = GridSearchCV(model, params, scoring=mse, cv=crossvals)\n",
    "\n",
    "    # Run Grid Search\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    y_pred = gridsearch.predict(X_test)\n",
    "    MSE_test_set = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean squared error (test set): {MSE_test_set:.4}')\n",
    "    if plot:\n",
    "        # plot\n",
    "        plt.figure()\n",
    "        plt.title('Scores for every degree (per fold different colors)')\n",
    "        colors = ['b.', 'r.', 'g.', 'y.', 'k.', 'c.']\n",
    "        for i in range(crossvals):\n",
    "            q = gridsearch.cv_results_[f'split{i}_test_score']\n",
    "            plt.plot(np.log(params['lasso__alpha']), np.log(-q), colors[i%len(colors)], markersize=12)\n",
    "\n",
    "        plt.xlabel('log2 alpha')\n",
    "        plt.ylabel('log(-MSE)')\n",
    "        plt.legend(list(range(1,crossvals+1)))\n",
    "\n",
    "        # plot 2\n",
    "        plt.figure()\n",
    "        #plt.errorbar(np.log(params['lasso__alpha']), np.log(-gridsearch.cv_results_[f'mean_test_score']), np.log(gridsearch.cv_results_[f'std_test_score']), linestyle='None', marker='.',markersize=12)\n",
    "        plt.plot(np.log(params['lasso__alpha']), np.log(-gridsearch.cv_results_[f'mean_test_score']), 'k.', markersize=12)\n",
    "        plt.title('Average scores of all folds')\n",
    "        plt.xlabel('log2 alpha')\n",
    "        plt.ylabel('log(-MSE)');\n",
    "    return gridsearch\n",
    "\n",
    "gene_expression = pd.read_csv(\"./data/RNA_expression_curated.csv\", sep=',', header=0, index_col=0)\n",
    "drug_response = pd.read_csv(\"./data/drug_response_curated.csv\", sep=',', header=0, index_col=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(gene_expression, drug_response)\n",
    "\n",
    "alphaspace = np.logspace(-3, 1, num=15)\n",
    "# Find optimal alpha\n",
    "grids = do_gridsearch_alpha(X_train, y_train, X_test, y_test, alphaspace, 5)\n",
    "alphamin = grids.best_params_['lasso__alpha']\n",
    "print(alphamin)\n",
    "\n",
    "\n",
    "feature_index = np.nonzero(grids.best_estimator_.named_steps['lasso'].coef_)\n",
    "print(f\"The selected features are: {gene_expression.columns.values[feature_index]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "Look at the features selected using the hyperparameter which corresponds to the minimum cross-validation error.\n",
    "\n",
    "<p><font color='#770a0a'>Is the partition in training and validation sets playing a role in the selection of the hyperparameter? How will this affect the selection of the relevant features?</font></p>\n",
    "\n",
    "<p><font color='#770a0a'>Should the value of the intercept also be shrunk to zero with Lasso and Ridge regression? Motivate your answer.</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "Partitioning in training and validation do play a role in selection of alpha as we can see in the different cross validation runs above, some subsets have the minimum at different points than others/the average. Different alphas will leave more or less features in the final model and thus affect the selection of features.\n",
    "\n",
    "<font color='#FF0000'>Discussiepuntje Troy: Zouden we dit moeten aantonen voor de RNA expression dataset? Er wordt namelijk in de eerste zin gezegd 'look at the features selected using the hyperparameter ... '. Zo ja, Dit kunnen we op de volgende manier voor elkaar krijgen (wil ik wel doen, maar graag eerst even bespreken voor het geval jullie dit niet nodig vinden ;)): </font>\n",
    "<br>\n",
    "`best_alphas_per_K=[]`, `features_per_K=[]`\n",
    "> Voor $K=1\\,,2\\,,\\ldots\\,,N$ (bv. $N=10$):\n",
    ">>  `hyperparam_selector = GridSearch(K)`\n",
    "    <br>`best_alpha = hyperparam_selector.best_params_['lasso__alpha']`\n",
    "    <br>\n",
    "    <br>`selected_features_idx = np.nonzero(grids.best_estimator_.named_steps['lasso'].coef_)`\n",
    "    <br>`selected_features = gene_expression.columns.values[feature_index]`\n",
    "    <br>\n",
    "    <br>`best_alphas_per_K.append(best_alpha)`\n",
    "    <br>`features_per_K.append(selected_features)`\n",
    "\n",
    "Eventueel nog voor 2 of meer verschillende data shuffles + seed in het algemeen voor de lasso solver. \n",
    "\n",
    "The intercept should be seperate, as the intercept is merely a correction of the mean in a complex feature space and thus not relate to whether a feature has high enough impact and robustness to be taken into account in the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.48306306])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the resulting coefficients for the best estimator (best alpha) -->\n",
    "# Effect of training and val sets: rerun and check if below func is different\n",
    "grids.best_estimator_.steps[1][1].coef_\n",
    "# As we can see Lasso automatically seperates the intercept from the Regularization --> It is and should not be included\n",
    "grids.best_estimator_.steps[1][1].intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-variance \n",
    "\n",
    "Show the effect of the regularization on the parameter estimates in terms of bias and variance. For this you can repeat the optimization 100 times using bootstrap and visualise the profile of the Lasso regression coefficient over a grid of the hyperparameter, optionally including the variability as error bars.\n",
    "\n",
    "<p><font color='#770a0a'>Based on the visual analysis of the plot, what are your observation on bias and variance in relation to model complexity? Motivate your answer.</font></p>\n",
    "\n",
    "<font color='#FF0000'>Troy: Ik heb het nu zonder grid search gedaan. GridSearchCV heeft geen ondersteuning voor het retrieven van alle model coëfficiënten, alleen van de beste. Vorig jaar heb ik dit opgelost door een clone van GridSearchCV te maken en die zelf aan te passen (uiteraard in eigen code). Nu bedenk ik me wel dat GridSearch misschien helemaal niet nodig, aangezien er verder niet gevraagd wordt cross-validation toe te passen.   </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1868389747333207, tolerance: 0.08938402270270271\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10569852327901312, tolerance: 0.0803819936936937\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08363917593681658, tolerance: 0.0803819936936937\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08486508233023005, tolerance: 0.0803819936936937\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10320518893033759, tolerance: 0.08336047081081081\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11627037822532962, tolerance: 0.0951473299099099\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11883203060416127, tolerance: 0.08855916432432433\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14848498275146638, tolerance: 0.09345677189189189\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14574699330296137, tolerance: 0.0858420963963964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11120438214843364, tolerance: 0.0858420963963964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14523697672586633, tolerance: 0.0858420963963964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09568313411627244, tolerance: 0.08719228270270271\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13554059135003088, tolerance: 0.08251109693693694\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08811677009347596, tolerance: 0.08251109693693694\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.23265531857389868, tolerance: 0.08108393855855857\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1164415742199281, tolerance: 0.08822385855855856\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10643623032609939, tolerance: 0.10239683747747749\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1495412483431377, tolerance: 0.0867435881081081\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09558131780468035, tolerance: 0.0867435881081081\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08902225389579765, tolerance: 0.0867435881081081\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2663115692193803, tolerance: 0.0791878827027027\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17987683384503528, tolerance: 0.07222829423423424\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07171074974846647, tolerance: 0.0652931681081081\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08437451670867914, tolerance: 0.07098154810810813\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07626352890155574, tolerance: 0.07098154810810813\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09488937506235026, tolerance: 0.07982156756756756\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0983501178064575, tolerance: 0.08098032774774774\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10557621761762553, tolerance: 0.0939782772972973\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10028607186833736, tolerance: 0.08712555027027027\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2716229710327273, tolerance: 0.09289655243243242\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10943404904704096, tolerance: 0.08989792396396395\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17831839294585236, tolerance: 0.09825501693693693\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11018997838179834, tolerance: 0.09825501693693693\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18831524665539257, tolerance: 0.10089725693693694\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1639266910747422, tolerance: 0.08407072396396396\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3475220554275384, tolerance: 0.0693618336936937\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12829160346473195, tolerance: 0.0717347099099099\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10451977625184847, tolerance: 0.05310367423423425\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.19094897999271093, tolerance: 0.08991353963963965\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.126826082873635, tolerance: 0.09483425963963964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5190484893292061, tolerance: 0.09713444234234235\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14397327830043527, tolerance: 0.0815850255855856\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09325698258263987, tolerance: 0.08746097423423424\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1434324796792001, tolerance: 0.07325497477477477\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14543380994554794, tolerance: 0.09091995693693694\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11517673810329515, tolerance: 0.09091995693693694\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1050210842185914, tolerance: 0.08189256342342342\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13848671705059262, tolerance: 0.0854675763963964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08507552809137199, tolerance: 0.08194530702702703\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.155355937578265, tolerance: 0.07996326558558559\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08433947444152351, tolerance: 0.07996326558558559\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09419244521291668, tolerance: 0.08676139477477478\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14265656901436358, tolerance: 0.08467688756756757\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09720502437611604, tolerance: 0.07580505027027028\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15704772488999233, tolerance: 0.07580505027027028\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09301448682650687, tolerance: 0.08310813369369369\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11742998360034154, tolerance: 0.09420305099099101\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17425652231720454, tolerance: 0.08911387963963964\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1108143045041315, tolerance: 0.0802500027027027\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11379518531517732, tolerance: 0.0802500027027027\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Troy\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.19876425338214743, tolerance: 0.07942440396396397\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "gene_expression = pd.read_csv(\"./data/RNA_expression_curated.csv\", sep=',', header=0, index_col=0)\n",
    "drug_response = pd.read_csv(\"./data/drug_response_curated.csv\", sep=',', header=0, index_col=0)\n",
    "scorer = 'neg_mean_squared_error'\n",
    "\n",
    "alphaspace = np.logspace(-3, 1, num=15)\n",
    "\n",
    "def bootstrap_test_train_split(X: np.ndarray, y: np.ndarray, n_bootstrap_runs: int,\n",
    "                               random_state: int = 0) -> \\\n",
    "                                    typing.Iterator[typing.Tuple[np.ndarray,\n",
    "                                                                 np.ndarray,\n",
    "                                                                 np.ndarray,\n",
    "                                                                 np.ndarray]]:\n",
    "    \"\"\"\n",
    "    A generator that samples X, y with replacement (used in bootstrapping) and splits\n",
    "    into test ,train\n",
    "\n",
    "    :param X: feature matrix\n",
    "    :param y: target vector\n",
    "    :param n_bootstrap_runs: amount of times the data is resampled\n",
    "    :param random_state: random state of random number generators\n",
    "    :yield: X and y resampled and split into train, test (X_train, X_test, y_train, y_test)\n",
    "    \"\"\"\n",
    "    for i in range(n_bootstrap_runs):\n",
    "        # Bootstrapping is sampling WITH replacement\n",
    "        Xsampled, ysampled = resample(X, y, random_state=random_state+i, replace=True)\n",
    "\n",
    "        yield train_test_split(Xsampled, ysampled, shuffle=False)\n",
    "\n",
    "    \n",
    "\n",
    "MSEs = np.zeros((100, alphaspace.shape[0]))\n",
    "coefs = np.zeros((100, alphaspace.shape[0], gene_expression.shape[1]))\n",
    "\n",
    "for i, (X_train, X_test, y_train, y_test) in enumerate(bootstrap_test_train_split(gene_expression,\n",
    "                                                                                drug_response,\n",
    "                                                                                100,\n",
    "                                                                                40)):\n",
    "    Lassoreg = Lasso(max_iter=10000)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Define the pipeline\n",
    "    model = Pipeline([\n",
    "                     (\"scaler\", scaler),\n",
    "                     (\"lasso\", Lassoreg)\n",
    "                    ])\n",
    "    \n",
    "    params = {'lasso__alpha': alphaspace}\n",
    "    \n",
    "    for j, param in enumerate(ParameterGrid(params)): \n",
    "        model_ = clone(model)\n",
    "              \n",
    "        model_.set_params(**param)\n",
    "    \n",
    "        model_.fit(X_train, y_train)\n",
    "              \n",
    "        y_pred = model_.predict(X_test)\n",
    "              \n",
    "        MSEs[i, j] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        coefs[i, j, ...] = model_.named_steps['lasso'].coef_\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: plotting + answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "<p><font color='#770a0a'>Write the expression of the objective function for the penalized logistic regression with $L_1$ and $L_2$ regularisation (as in Elastic net).</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
