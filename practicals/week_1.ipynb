{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the practicals\n",
    "\n",
    "***These notebooks are best viewed in Jupyter. GitHub might not display all content of the notebook properly.***\n",
    "\n",
    "## Goal of the practical exercises\n",
    "\n",
    "The exercises have two goals:\n",
    "\n",
    "1. Give you the opportunity to obtain 'hands-on' experience in implementing, training and evaluation machine learning models in Python. This experience will also help you better understand the theory covered during the lectures. \n",
    "\n",
    "2. Occasionally demonstrate some 'exam-style' questions that you can use as a reference when studying for the exam. Note however that the example questions are (as the name suggests) only examples and do not constitute a complete and sufficient list of 'things that you have to learn for the exam'. You can recognize example questions as (parts of) exercises by <font color=\"#770a0a\">this font color</font>.\n",
    "\n",
    "For each set of exercises (one Python notebook such as this one $==$ one set of exercises) you have to submit deliverables that will then be graded and constitute 25% of the final grade. Thus, the work that you do during the practicals has double contribution towards the final grade: as 25% direct contribution and as a preparation for the exam that will define the other 65% of the grade.\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "For each set of exercises, you have to submit:\n",
    "1. Python functions and/or classes (`.py` files) that implement basic functionalities (e.g. a $k$-NN classifier) and \n",
    "2. A *single* Python notebook that contains the experiments, visualization and answer to the questions and math problems. *Do not submit your answers as Word or PDF documents (they will not be graded)*. The submitted code and notebook should run without errors and be able to fully reproduce the reported results.\n",
    "\n",
    "We recommend that you clone the provided notebooks (such as this one) and write your code in them. The following rubric will be used when grading the practical work:\n",
    "\n",
    "Component  | Insufficient | Satisfactory | Excellent\n",
    "--- | --- | --- | ---\n",
    "**Code** | Missing or incomplete code structure, runs with errors, lacks documentation | Self-contained, does not result in errors, contains some documentation, can be easily used to reproduce the reported results | User-friendly, well-structured (good separation of general functionality and experiments, i.e. between `.py` files and the Pyhthon notebook), detailed documentation, optimized for speed, <s>use of a version control system (such as GitHub)</s>\n",
    "**Answers to questions** | Incorrect, does not convey understanding of the material, appears to be copied from another source | Correct, conveys good understanding of the material, description in own words | Correct, conveys excellent level of understanding, makes connections between topics\n",
    "\n",
    "## A word on notation\n",
    "\n",
    "When we refer to Python variables, we will use a monospace font. For example, `X` is a Python variable that contains the data matrix. When we refer to mathematical variables, we will use the de-facto standard notation: $a$ or $\\lambda$ is a scalar variable, $\\boldsymbol{\\mathrm{w}}$ is a vector and $\\boldsymbol{\\mathrm{X}}$ is a matrix (e.g. a data matrix from the example above). You should use the same notation when writing your answers and solutions.\n",
    "\n",
    "# Two simple machine learning models\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Throughout the practical curriculum of this course, we will use the Python programming language and its ecosystem of libraries for scientific computing (such as `numpy`, `scipy`, `matplotlib`, `scikit-learn` etc). The practicals for the deep learning part of the course will use the `keras` deep learning framework. If you are not sufficiently familiar with this programming language and/or the listed libraries and packages, you are strongly advised to go over the corresponding tutorials from the ['Essential skills'](https://github.com/tueimage/essential-skills) module (the `scikit-learn` library is not covered by the tutorial, however, an extensive documentation is available [here](https://scikit-learn.org/stable/documentation.html).\n",
    "\n",
    "In this first set of exercises, we will use two toy datasets that ship together with `scikit-learn`. \n",
    "\n",
    "#### Dataset information\n",
    "\n",
    "The first dataset is named `diabetes` and contains 442 patients described with 10 features: age, sex, body mass index, average blood pressure, and six blood serum measurements. The target variable is a continuous quantitative measure of the disease (diabetes) progression one year after the baseline measurements were recorded. More information is available [here](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/datasets/descr/diabetes.rst) and [here](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html).\n",
    "\n",
    "The second dataset is named `breast_cancer` and is a copy of the UCI ML Breast Cancer Wisconsin (Diagnostic) datasets (more infortmation is available [here](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/datasets/descr/breast_cancer.rst) and [here](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)). The datasets contains of 569 instances represented with 30 features that are computed from a images of a fine needle aspirate of a breast mass. The features describe characteristics of the cell nuclei present in the image. Each instance is associated with a binary target variable ('malignant' or 'benign'). \n",
    "\n",
    "You can load the two datasets in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes, load_breast_cancer\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the majority of the exercises in this course, we will use higher-level libraries and packages such as `scikit-learn` and `keras` to implement, train and evaluate machine learning models. However, the goal of this first set of exercises is to illustrate basic mathematical tools and machine learning concepts. Because of this, we will impose a restriction of only using basic `numpy` functionality. Furthermore, you should as much as possible restrict the use of for-loops (e.g. use a vector-to-matrix product instead of a for loop when appropriate).\n",
    "\n",
    "If `X` is a 2D data matrix, we will use the convention that the rows of the matrix contain the samples (or instances) and the columns contain the features (inputs to the model). That means that a data matrix with a shape `(122, 13)` represents a dataset with 122 samples, each represented with 13 features. Similarly, if `Y` is a 2D matrix containing the targets, the rows correspond to the samples and the columns to the different targets (outputs of the model). Thus, if the shape of `Y` is `(122, 3)` that means that there are 122 samples and each sample is has 3 targets (note that in the majority of the examples we will only have a single target and thus the number of columns of `Y` will be 1).\n",
    "\n",
    "You can obtain the data and target matrices from the two datasets in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442, 1)\n"
     ]
    }
   ],
   "source": [
    "X = diabetes.data\n",
    "Y = diabetes.target[:, np.newaxis]\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to only use a subset of the available features, you can obtain a reduced data matrix in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 1)\n",
      "(442, 2)\n"
     ]
    }
   ],
   "source": [
    "# use only the fourth feature\n",
    "X = diabetes.data[:, np.newaxis, 3]\n",
    "print(X.shape)\n",
    "\n",
    "# use the third, and tenth features\n",
    "X = diabetes.data[:, (3,9)]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Question***: Why we need to use the `np.newaxis` expression in the examples above? \n",
    "\n",
    "***Answer***: When a single feature is used, usually, a 1D-array is created (when doing `X = diabetes.data[:,3]`). With `np.newaxis`, a new 'axis' (the column of a 2D array) is added to properly format the data. This holds up for both the feature array (`X`) and the target array (`Y`).\n",
    "\n",
    "Note that in all your experiments in the exercises, you should use and independent training and testing sets. You can split the dataset into a training and testing subsets in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1)\n",
      "(300, 1)\n",
      "(142, 1)\n",
      "(142, 1)\n"
     ]
    }
   ],
   "source": [
    "# use the fourth feature\n",
    "# use the first 300 training samples for training, and the rest for testing\n",
    "X_train = diabetes.data[:300, np.newaxis, 3]\n",
    "y_train = diabetes.target[:300, np.newaxis]\n",
    "X_test = diabetes.data[300:, np.newaxis, 3]\n",
    "y_test = diabetes.target[300:, np.newaxis]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Linear regression\n",
    "\n",
    "Implement training and evaluation of a linear regression model on the diabetes dataset using only matrix multiplication, inversion and transpose operations. Report the mean squared error of the model.\n",
    "\n",
    "To get you started we have implemented the first part of this exercise (fitting of the model) as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 152.34786452]\n",
      " [ -16.57607993]\n",
      " [-254.66532396]\n",
      " [ 560.98630022]\n",
      " [ 278.91811152]\n",
      " [-393.41357305]\n",
      " [  97.05460405]\n",
      " [ -19.0023093 ]\n",
      " [ 169.46450327]\n",
      " [ 632.95050374]\n",
      " [ 114.21638941]]\n",
      "Mean squared error: 2794.57\n"
     ]
    }
   ],
   "source": [
    "# add subfolder that contains all the function implementations\n",
    "# to the system path so we can import them\n",
    "import sys\n",
    "sys.path.append('code/')\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# the actual implementation is in linear_regression.py,\n",
    "# here we will just use it to fit a model\n",
    "from linear_regression import *\n",
    "\n",
    "# load the dataset\n",
    "# same as before, but now we use all features\n",
    "X_train = diabetes.data[:300, :]\n",
    "y_train = diabetes.target[:300, np.newaxis]\n",
    "X_test = diabetes.data[300:, :]\n",
    "y_test = diabetes.target[300:, np.newaxis]\n",
    "\n",
    "beta = lsq(X_train, y_train)\n",
    "\n",
    "# print the parameters\n",
    "print(beta)\n",
    "\n",
    "y_test_pred = fit_to_model(beta, X_test)\n",
    "MSE = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\"Mean squared error: {:.2f}\".format(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted linear regression <font color='#FF0000'>(correct implementation?)</font>\n",
    "\n",
    "Assume that in the dataset that you use to train a linear regression model, there are identical versions of some samples. This problem can be reformulated to a weighted linear regression problem where the matrices $\\boldsymbol{\\mathrm{X}}$ and $\\boldsymbol{\\mathrm{Y}}$ (or the vector $\\boldsymbol{\\mathrm{y}}$ if there is only a single target/output variable) contain only the unique data samples, and a vector $\\boldsymbol{\\mathrm{d}}$ is introduced that gives more weight to samples that appear multiple times in the original dataset (for example, the sample that appears 3 times has a corresponding weight of 3). \n",
    "\n",
    "<p><font color='#770a0a'>Derive the expression for the least-squares solution of a weighted linear regression model (note that in addition to the matrices $\\boldsymbol{\\mathrm{X}}$ and $\\boldsymbol{\\mathrm{Y}}$, the solution should include a vector of weights $\\boldsymbol{\\mathrm{d}}$).</font></p>\n",
    "\n",
    "***Answer***: Multiply every $\\beta$ with the corresponding weight. In that way, every feature will have its own 'weight'. This can be done by doing:\n",
    "\n",
    "$\\boldsymbol{\\mathrm{Y}} = \\boldsymbol{\\mathrm{X}} \\cdot (\\mathrm{diag}(\\boldsymbol{\\mathrm{d}})\\cdot\\boldsymbol{\\mathrm{\\beta}}) + \\epsilon$\n",
    "\n",
    "Here, $\\mathrm{diag}(\\boldsymbol{\\mathrm{d}})$ is a matrix with the weights on the diagonal.\n",
    "This can be rewritten to:\n",
    "\n",
    "$\\boldsymbol{\\mathrm{Y}} = (\\boldsymbol{\\mathrm{X}} \\cdot \\mathrm{diag}(\\boldsymbol{\\mathrm{d}}))\\cdot\\boldsymbol{\\mathrm{\\beta}} + \\epsilon\\quad$ (associative law of multiplication)\n",
    "\n",
    "Now multiply both sides with $\\boldsymbol{\\mathrm{X^T}}$ and invert this matrix:\n",
    "\n",
    "$\\boldsymbol{\\mathrm{\\beta}} = (\\boldsymbol{\\mathrm{X^T}} \\cdot\\boldsymbol{\\mathrm{X}} \\cdot \\mathrm{diag}(\\boldsymbol{\\mathrm{d}}))^{-1} \\cdot \\boldsymbol{\\mathrm{X^T}} \\boldsymbol{\\mathrm{Y}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149.42230855]\n",
      " [ -2.07236747]\n",
      " [-12.86075972]\n",
      " [ 25.2606507 ]\n",
      " [ 13.04795994]\n",
      " [-16.70601384]\n",
      " [  3.13671807]\n",
      " [ -1.66787837]\n",
      " [  7.64610591]\n",
      " [ 29.64282316]\n",
      " [  5.42038996]]\n",
      "Mean squared error: 2882.85\n"
     ]
    }
   ],
   "source": [
    "# add subfolder that contains all the function implementations\n",
    "# to the system path so we can import them\n",
    "import sys\n",
    "sys.path.append('code/')\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# the actual implementation is in linear_regression.py,\n",
    "# here we will just use it to fit a model\n",
    "from linear_regression import *\n",
    "\n",
    "# load the dataset\n",
    "# same as before, but now we use all features\n",
    "X_train = diabetes.data[:300, :]\n",
    "X_train = np.append(X_train, diabetes.data[:15], axis=0)\n",
    "y_train = diabetes.target[:300, np.newaxis]\n",
    "X_test = diabetes.data[300:, :]\n",
    "y_test = diabetes.target[300:, np.newaxis]\n",
    "\n",
    "X_train, idxs, counts = np.unique(X_train, axis=0, return_index=True, return_counts=True)\n",
    "y_train = y_train[idxs]\n",
    "\n",
    "# Define the weights and run the weighted lsq \n",
    "beta = wlsq(X_train, y_train, counts)\n",
    "\n",
    "# print the parameters\n",
    "print(beta)\n",
    "\n",
    "# Predict the targets of \n",
    "y_test_pred = fit_to_model(beta, X_test)\n",
    "MSE = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Mean squared error: {:.2f}\".format(MSE))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-NN classification\n",
    "\n",
    "Implement a $k$-Nearest neighbors classifier from scratch in Python using only basic matrix operations with `numpy` and `scipy`. Train and evaluate the classifier on the breast cancer dataset, using all features. Show the performance of the classifier for different values of $k$ (plot the results in a graph). Note that for optimal results, you should normalize the features (e.g. to the $[0, 1]$ range or to have a zero mean and unit standard deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add subfolder that contains all the function implementations\n",
    "# to the system path so we can import them\n",
    "import sys\n",
    "sys.path.append('code/')\n",
    "\n",
    "# Reload the imports for every run\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import required libraries\n",
    "from linear_regression import *\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data\n",
    "X_train = breast_cancer.data[:400, :]\n",
    "y_train = breast_cancer.target[:400, np.newaxis]\n",
    "X_test = breast_cancer.data[400:, :]\n",
    "y_test = breast_cancer.target[400:, np.newaxis]\n",
    "\n",
    "# normalize data\n",
    "X_train = normalize(X_train)\n",
    "X_test  = normalize(X_test)\n",
    "\n",
    "# predict labels using k-NN method\n",
    "y_test_pred = kNN(X_train, y_train, X_test, k=5)\n",
    "\n",
    "# calculate F-score\n",
    "test_score = f1_score(y_test, y_test_pred)  # accuracy metric can also be used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16fb389a550>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try for different values of 'k'\n",
    "\n",
    "ks = [1,3,5,7,9,11,13,15]\n",
    "scores = []\n",
    "for k in ks:\n",
    "    y_test_pred = kNN(X_train, y_train, X_test, k)\n",
    "    scores.append(f1_score(y_test, y_test_pred))\n",
    "\n",
    "plt.plot(ks, scores, 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-NN regression\n",
    "\n",
    "Modify the $k$-NN implementation to do regression instead of classification. Compare the performance of the linear regression model and the $k$-NN regression model on the diabetes dataset for different values of $k$.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 3556.65\n"
     ]
    }
   ],
   "source": [
    "# add subfolder that contains all the function implementations\n",
    "# to the system path so we can import them\n",
    "import sys\n",
    "sys.path.append('code/')\n",
    "\n",
    "# reload libraries for every run\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import required libraries\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from linear_regression import *\n",
    "\n",
    "# Import data\n",
    "X_train = diabetes.data[:300, :]\n",
    "y_train = diabetes.target[:300, np.newaxis]\n",
    "X_test = diabetes.data[300:, :]\n",
    "y_test = diabetes.target[300:, np.newaxis]\n",
    "\n",
    "# normalize data\n",
    "X_train = normalize(X_train)\n",
    "X_test  = normalize(X_test)\n",
    "\n",
    "# Predict labels using the k-NN method\n",
    "y_test_pred = kNN(X_train, y_train, X_test, k=5, mode='regression')\n",
    "\n",
    "# calculate mean squared error\n",
    "MSE = mean_squared_error(y_test, y_test_pred)\n",
    "print(\"Mean squared error: {:.2f}\".format(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16fb395d6d8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXnUlEQVR4nO3dfYxd9X3n8ffH5iExG2o7DKxjG4ZkHdIkah3vrSGLFKkhsQ2JMJESrVfu4qVI02hJlu5DE7xIS5vUq642XRLUrqspTyadxqVuEBZKIQ6kWlVaHq6DITyup8EPEzt4IgPdxBJZ4LN/nJ/DtbkzcweP597r83lJo3vP9/zune9B1597+J0z58g2ERFRD3O63UBERMyehH5ERI0k9CMiaiShHxFRIwn9iIgaOa3bDUzmnHPO8eDgYLfbiIjoKzt37vyp7YF263o69AcHB2k2m91uIyKir0jaO9G6Kad3JF0kaVfLzz9K+l1JCyXtkLS7PC4o4yXpFkmjkp6UtKLlvTaU8bslbZiZzYuIiE5NGfq2n7e93PZy4J8DR4B7gBuAB20vAx4sywCXA8vKzxCwGUDSQuAm4GJgJXDT0S+KiIiYHdM9kHsZ8A+29wJrgS2lvgW4qjxfC9zlysPAfEmLgNXADtuHbb8E7ADWnPAWREREx6Yb+uuAb5Xn59k+CFAezy31xcD+lteMldpE9WNIGpLUlNQcHx+fZnsRETGZjkNf0hnAlcBfTzW0Tc2T1I8t2MO2G7YbAwNtDz5HRMTbNJ09/cuBH9h+sSy/WKZtKI+HSn0MWNryuiXAgUnqM25kBAYHYc6c6nFk5GT8loiI/jOd0P9XvDm1A7AdOHoGzgbg3pb61eUsnkuAV8r0zwPAKkkLygHcVaU2o0ZGYGgI9u4Fu3ocGkrwR0QAqJNLK0uaRzUf/17br5Tau4G7gfOBfcDnbB+WJOBPqA7SHgGusd0sr/lt4D+Xt91k+47Jfm+j0fB0z9MfHKyC/ngXXAB79kzrrSIi+pKknbYbbdf18vX0307oz5lT7eEfT4I33pihxiIiethkoX/KXXvn/POnV4+IqJNTLvQ3bYJ5846tzZtX1SMi6u6UC/3162F4uJrDl6rH4eGqHhFRdz19wbW3a/36hHxERDun3J5+RERMLKEfEVEjCf2IiBpJ6EdE1EhCPyKiRhL6ERE1ktCPiKiRhH5ERI0k9CMiaiShHxFRIwn9iIgaSehHRNRIR6Evab6kbZKek/SspI9K+n1JP5a0q/xc0TJ+o6RRSc9LWt1SX1Nqo5JuOBkbFBERE+v0KpvfAO63/VlJZwDzgNXAzba/1jpQ0geBdcCHgPcA35P0/rL6T4FPUt0k/TFJ220/MwPbERERHZgy9CWdDXwM+DcAtn8B/KK6FW5ba4Gttl8FXpA0Cqws60Zt/6i879YyNqEfETFLOpneeS8wDtwh6XFJt0o6q6z7gqQnJd0uaUGpLaa6ifpRY6U2UT0iImZJJ6F/GrAC2Gz7I8DPgRuAzcD7gOXAQeCPy/h2/wvgSerHkDQkqSmpOT4+3kF7ERHRqU5CfwwYs/1IWd4GrLD9ou3Xbb8B/DlvTuGMAUtbXr8EODBJ/Ri2h203bDcGBgamtzURETGpKUPf9k+A/ZIuKqXLgGckLWoZ9hngqfJ8O7BO0pmSLgSWAY8CjwHLJF1YDgavK2MjImKWdHr2zheBkRLWPwKuAW6RtJxqimYP8DsAtp+WdDfVAdrXgOtsvw4g6QvAA8Bc4HbbT8/gtkRExBRkv2VavWc0Gg03m81utxER0Vck7bTdaLcuf5EbEVEjCf2IiBpJ6EdE1EhCPyKiRhL6ERE1ktCPiKiRhH5ERI0k9CMiaiShHxFRIwn9iIgaSehHRNRIQj8iokYS+hERNZLQj4iokYR+RESNJPQjImokoR8RUSMdhb6k+ZK2SXpO0rOSPippoaQdknaXxwVlrCTdImlU0pOSVrS8z4YyfrekDSdroyIior1O9/S/Adxv+wPArwPPAjcAD9peBjxYlgEup7oZ+jJgCNgMIGkhcBNwMbASuOnoF0VERMyOKUNf0tnAx4DbAGz/wvbLwFpgSxm2BbiqPF8L3OXKw8B8SYuA1cAO24dtvwTsANbM6NZERMSkOtnTfy8wDtwh6XFJt0o6CzjP9kGA8nhuGb8Y2N/y+rFSm6h+DElDkpqSmuPj49PeoIiImFgnoX8asALYbPsjwM95cyqnHbWpeZL6sQV72HbDdmNgYKCD9iIiolOdhP4YMGb7kbK8jepL4MUybUN5PNQyfmnL65cAByapR0TELJky9G3/BNgv6aJSugx4BtgOHD0DZwNwb3m+Hbi6nMVzCfBKmf55AFglaUE5gLuq1CIiYpac1uG4LwIjks4AfgRcQ/WFcbeka4F9wOfK2O8AVwCjwJEyFtuHJX0VeKyM+4rtwzOyFRER0RHZb5lW7xmNRsPNZrPbbURE9BVJO2032q3LX+RGRNRIQj8iokYS+hERNZLQj4iokYR+RESNJPQjImokoR8RUSMJ/YiIGknoR0TUSEI/IqJGEvoRETWS0I+IqJGEfkREjST0IyJqJKEfEVEjCf2IiBpJ6EdE1EhHoS9pj6QfStolqVlqvy/px6W2S9IVLeM3ShqV9Lyk1S31NaU2KumGmd+ciIiYTKf3yAX4Tds/Pa52s+2vtRYkfRBYB3wIeA/wPUnvL6v/FPgkMAY8Jmm77WfeXusRETFd0wn9Tq0Fttp+FXhB0iiwsqwbtf0jAElby9iEfkTELOl0Tt/AdyXtlDTUUv+CpCcl3S5pQaktBva3jBkrtYnqx5A0JKkpqTk+Pt7xhkRExNQ6Df1Lba8ALgeuk/QxYDPwPmA5cBD44zJWbV7vSerHFuxh2w3bjYGBgQ7bi4iITnQU+rYPlMdDwD3AStsv2n7d9hvAn/PmFM4YsLTl5UuAA5PUIyJilkwZ+pLOkvSuo8+BVcBTkha1DPsM8FR5vh1YJ+lMSRcCy4BHgceAZZIulHQG1cHe7TO3KRERMZVODuSeB9wj6ej4v7R9v6RvSlpONUWzB/gdANtPS7qb6gDta8B1tl8HkPQF4AFgLnC77adneHsiImISst8yrd4zGo2Gm81mt9uIiOgrknbabrRbl7/IjYiokYR+RESNJPQjImokoR8RUSMJ/YiIGknoR0TUSEI/IqJGEvoRETWS0I+IqJGEfkREjST0IyJqJKEfEVEjCf2IiBpJ6EdE1EhCPyKiRhL6ERE1ktCPiKiRjkJf0h5JP5S0S1Kz1BZK2iFpd3lcUOqSdIukUUlPSlrR8j4byvjdkjacnE2KiIiJTGdP/zdtL2+5BdcNwIO2lwEPlmWAy6luhr4MGAI2Q/UlAdwEXAysBG46+kURERGz40Smd9YCW8rzLcBVLfW7XHkYmC9pEbAa2GH7sO2XgB3AmhP4/RERMU2dhr6B70raKWmo1M6zfRCgPJ5b6ouB/S2vHSu1ierHkDQkqSmpOT4+3vmWRETElE7rcNyltg9IOhfYIem5ScaqTc2T1I8t2MPAMECj0XjL+oiIePs62tO3faA8HgLuoZqTf7FM21AeD5XhY8DSlpcvAQ5MUo+IiFkyZehLOkvSu44+B1YBTwHbgaNn4GwA7i3PtwNXl7N4LgFeKdM/DwCrJC0oB3BXlVpERMySTqZ3zgPukXR0/F/avl/SY8Ddkq4F9gGfK+O/A1wBjAJHgGsAbB+W9FXgsTLuK7YPz9iWRETElGT37rR5o9Fws9nsdhsREX1F0s6W0+uPkb/IjYiokYR+RESNJPQjImokoR8RUSMJ/YiIGknoR0TUSEI/IqJGEvoRETWS0I+IqJGEfkREjST0IyJqJKEfEVEjCf2IiBpJ6EdE1EhCPyKiRhL6ERE1ktCPiKiRjkNf0lxJj0u6ryzfKekFSbvKz/JSl6RbJI1KelLSipb32CBpd/nZMNHvioiIk6OTe+QedT3wLHB2S+33bG87btzlwLLyczGwGbhY0kLgJqABGNgpabvtl95u8xERMT0d7elLWgJ8Cri1g+FrgbtceRiYL2kRsBrYYftwCfodwJq32XdERLwNnU7vfB34EvDGcfVNZQrnZklnltpiYH/LmLFSm6h+DElDkpqSmuPj4x22FxERnZgy9CV9Gjhke+dxqzYCHwB+A1gIfPnoS9q8jSepH1uwh203bDcGBgamai8iIqahkz39S4ErJe0BtgIfl/QXtg+WKZxXgTuAlWX8GLC05fVLgAOT1CMiYpZMGfq2N9peYnsQWAc8ZPu3yjw9kgRcBTxVXrIduLqcxXMJ8Irtg8ADwCpJCyQtAFaVWkREzJLpnL1zvBFJA1TTNruAz5f6d4ArgFHgCHANgO3Dkr4KPFbGfcX24RP4/RERMU2y3zKt3jMajYabzWa324iI6CuSdtputFuXv8iNiKiRhH5ERI0k9CMiaiShHxFRIwn9iIgaSehHRNRIQj8iokYS+hERNZLQj4iokYR+l42MwOAgzJlTPY6MdLujiDiVnci1d+IEjYzA0BAcOVIt791bLQOsX9+9viLi1JU9/S668cY3A/+oI0eqekTEyZDQ76J9+6ZXj4g4UQn9Ljr//OnVIyJOVEK/izZtgnnzjq3Nm1fVIyJOhoR+F61fD8PDcMEFIFWPw8M5iBsRJ0/O3umy9esT8hExezre05c0V9Ljku4ryxdKekTSbkl/JemMUj+zLI+W9YMt77Gx1J+XtHqmNyYiIiY3nemd64FnW5b/G3Cz7WXAS8C1pX4t8JLtfwbcXMYh6YNUN1b/ELAG+J+S5p5Y+xERMR0dhb6kJcCngFvLsoCPA9vKkC3AVeX52rJMWX9ZGb8W2Gr7VdsvUN04feVMbERERHSm0z39rwNfAt4oy+8GXrb9WlkeAxaX54uB/QBl/Stl/C/rbV7zS5KGJDUlNcfHx6exKRERMZUpQ1/Sp4FDtne2ltsM9RTrJnvNmwV72HbDdmNgYGCq9iIiYho6OXvnUuBKSVcA7wDOptrzny/ptLI3vwQ4UMaPAUuBMUmnAb8CHG6pH9X6moiImAVT7unb3mh7ie1BqgOxD9leD3wf+GwZtgG4tzzfXpYp6x+y7VJfV87uuRBYBjw6Y1sSERFTOpHz9L8MbJX0h8DjwG2lfhvwTUmjVHv46wBsPy3pbuAZ4DXgOtuvn8Dvj4iIaVK1E96bGo2Gm81mt9uIiOgrknbabrRbl8swRETUSEI/IqJGEvoRETWS0I+IqJGEfkREjST0IyJqJKEfEVEjCf2IiBpJ6EdE1EhCPyKiRhL6ERE1ktCPiKiRhH5ERI0k9CMiaiShH9MyMgKDgzBnTvU4MtLtjiJiOk7kJipRMyMjMDQER45Uy3v3VssA69d3r6+I6Fz29KNjN974ZuAfdeRIVY+I/jBl6Et6h6RHJT0h6WlJf1Dqd0p6QdKu8rO81CXpFkmjkp6UtKLlvTZI2l1+Nkz0O6M37ds3vXpE9J5OpndeBT5u+2eSTgf+XtLflnW/Z3vbceMvp7rp+TLgYmAzcLGkhcBNQAMwsFPSdtsvzcSGxMl3/vnVlE67ekT0hyn39F35WVk8vfxMdmPdtcBd5XUPA/MlLQJWAztsHy5BvwNYc2Ltx2zatAnmzTu2Nm9eVY+I/tDRnL6kuZJ2AYeogvuRsmpTmcK5WdKZpbYY2N/y8rFSm6h+/O8aktSU1BwfH5/m5sTJtH49DA/DBReAVD0OD+cgbkQ/6Sj0bb9uezmwBFgp6cPARuADwG8AC4Evl+Fq9xaT1I//XcO2G7YbAwMDnbQXs2j9etizB954o3pM4Ef0l2mdvWP7ZeDvgDW2D5YpnFeBO4CVZdgYsLTlZUuAA5PUIyJilnRy9s6ApPnl+TuBTwDPlXl6JAm4CniqvGQ7cHU5i+cS4BXbB4EHgFWSFkhaAKwqtYiImCWdnL2zCNgiaS7Vl8Tdtu+T9JCkAappm13A58v47wBXAKPAEeAaANuHJX0VeKyM+4rtwzO3KRERMRXZk52I012NRsPNZrPbbUSfGhmp/nBs377qtNJNm3IMIupB0k7bjXbrchmGOCXlkhER7eUyDHFKyiUjItpL6McpKZeMiGgvoR+npIkuDZFLRkTdJfTjlJRLRkS0l9CPU1IuGRHRXs7eiVPW+vUJ+YjjZU8/IqJGEvoRETWS0I+IqJGEfkSPGBmBwUGYM6d6HBnpdkfRDSf7c5ADuRE9IJeNCJidz0EuuBbRAwYH299/+IILqpvVRD3M1OdgsguuZXonogf022Uj+m0qql/6nY3PQUI/ogf002Ujjk5B7N0L9ptTEL0apP3U72x8DhL6ET2gny4b0W9XMO2nfmfjc9DJ7RLfIelRSU9IelrSH5T6hZIekbRb0l9JOqPUzyzLo2X9YMt7bSz15yWtnrnNiOhv/XTZiH6biuqnfmfjczDlgdxyD9yzbP9M0unA3wPXA/8B+LbtrZL+DHjC9mZJ/xb4Ndufl7QO+Iztfynpg8C3qG6g/h7ge8D7bb8+0e/OgdyI3tNvB537rd+ZcEIHcl35WVk8vfwY+DiwrdS3UN0cHWBtWaasv6x8cawFttp+1fYLVPfQXfk2ticiuqifpqKg//o92Tqa05c0V9Iu4BCwA/gH4GXbr5UhY8Di8nwxsB+grH8FeHdrvc1rIqJP9NNUFPRfvydbR3+cVaZglkuaD9wD/Gq7YeVRE6ybqH4MSUPAEMD5vXjqQkT03RVM+63fk2laZ+/Yfhn4O+ASYL6ko18aS4AD5fkYsBSgrP8V4HBrvc1rWn/HsO2G7cbAwMB02ouIiCl0cvbOQNnDR9I7gU8AzwLfBz5bhm0A7i3Pt5dlyvqHXB0t3g6sK2f3XAgsAx6dqQ2JiIipdTK9swjYImku1ZfE3bbvk/QMsFXSHwKPA7eV8bcB35Q0SrWHvw7A9tOS7gaeAV4DrpvszJ2IiJh5ufZORMQpJtfeiYgIoMf39CWNA23+rKKrzgF+2u0mpqGf+u2nXqG/+u2nXqG/+u3FXi+w3fZMmJ4O/V4kqTnR/zb1on7qt596hf7qt596hf7qt596hUzvRETUSkI/IqJGEvrTN9ztBqapn/rtp16hv/rtp16hv/rtp14zpx8RUSfZ04+IqJGEfkREjST0OyRpqaTvS3q23EHs+m73NJVySezHJd3X7V6mImm+pG2Sniv/jT/a7Z4mIunfl8/AU5K+Jekd3e6plaTbJR2S9FRLbaGkHeVOdzskLehmj60m6Pe/l8/Ck5LuOXr9r25r12vLuv8kyZLO6UZvnUrod+414D/a/lWqq4xeV+4G1suup7o4Xj/4BnC/7Q8Av06P9i1pMfDvgIbtDwNzKdeX6iF3AmuOq90APGh7GfBgWe4Vd/LWfncAH7b9a8D/ATbOdlMTuJO39oqkpcAngR68CeOxEvodsn3Q9g/K8/9LFUo9exMYSUuATwG3druXqUg6G/gY5aJ9tn9RLuPdq04D3lkuHT6PNpcI7ybb/4vqYoetWu9o13qnu65r16/t77bcpOlhqkuxd90E/20Bbga+RJt7hPSahP7bUG72/hHgke52MqmvU30I3+h2Ix14LzAO3FGmo26VdFa3m2rH9o+Br1Ht0R0EXrH93e521ZHzbB+EagcGOLfL/UzHbwN/2+0mJiLpSuDHtp/odi+dSOhPk6R/AvwN8Lu2/7Hb/bQj6dPAIds7u91Lh04DVgCbbX8E+Dm9Nf3wS2UufC1wIfAe4CxJv9Xdrk5dkm6kmlod6XYv7UiaB9wI/Jdu99KphP40SDqdKvBHbH+72/1M4lLgSkl7gK3AxyX9RXdbmtQYMGb76P85baP6EuhFnwBesD1u+/8B3wb+RZd76sSLkhYBlMdDXe5nSpI2AJ8G1rt3/6DofVQ7AE+Uf29LgB9I+qdd7WoSCf0OSRLVnPOztv9Ht/uZjO2NtpfYHqQ6yPiQ7Z7dG7X9E2C/pItK6TKqm+30on3AJZLmlc/EZfToQefjtN7RrvVOdz1J0hrgy8CVto90u5+J2P6h7XNtD5Z/b2PAivKZ7kkJ/c5dCvxrqr3mXeXnim43dQr5IjAi6UlgOfBfu9xPW+X/RrYBPwB+SPVvqKf+DF/St4D/DVwkaUzStcAfAZ+UtJvqLJM/6maPrSbo90+AdwE7yr+1P+tqk8UEvfaVXIYhIqJGsqcfEVEjCf2IiBpJ6EdE1EhCPyKiRhL6ERE1ktCPiKiRhH5ERI38f2q/lN9P6zC7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRY FOR DIFFERENT VALUES OF 'k'\n",
    "\n",
    "ks = [1,3,5,7,9,11,13,15]\n",
    "scores = []\n",
    "for k in ks:\n",
    "    y_test_pred = kNN(X_train, y_train, X_test, k, mode='regression')\n",
    "    scores.append(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "plt.plot(ks, scores, 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean squared error has increased compared to the linear regression model for every value of $k$. The optimal value of $k$ appears to be around $k=11$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class-conditional probability \n",
    "\n",
    "Compute and visualize the class-conditional probability (conditional probability where the class label is the conditional variable, i.e. $P(X = x \\mid Y = y_i)$ for all features in the breast cancer dataset. Assume a Gaussian distribution.\n",
    "\n",
    "<p><font color='#770a0a'>Based on visual analysis of the plots, which individual feature can best discriminate between the two classes? Motivate your answer.</font></p>\n",
    "\n",
    "ANSWER: From the figure below, feature 27 appears to have a clear distinction between positive and negative samples, and is therefore most suitable for discrimination between the two classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the imports for every run\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "\n",
    "# load data\n",
    "X_train = breast_cancer.data[:400, :]\n",
    "y_train = breast_cancer.target[:400, np.newaxis]\n",
    "X_test = breast_cancer.data[400:, :]\n",
    "y_test = breast_cancer.target[400:, np.newaxis]\n",
    "\n",
    "\n",
    "# Define subplots\n",
    "fig, axs = plt.subplots(6,5, figsize=(16,22))\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test  = normalize(X_test)\n",
    "\n",
    "plot = 'gaussian'\n",
    "\n",
    "for row in range(6):\n",
    "    for column in range(5):\n",
    "        i = row*5+column\n",
    "        negs = X_train[y_train.T[0]==0, i]\n",
    "        post = X_train[y_train.T[0]==1, i]\n",
    "        \n",
    "        \n",
    "        if plot=='gaussian':\n",
    "            x_values = np.arange(-5, 5, 0.1)\n",
    "\n",
    "            y_values_neg = scipy.stats.norm(np.mean(negs), np.std(negs))\n",
    "            y_values_pos = scipy.stats.norm(np.mean(post), np.std(post))\n",
    "\n",
    "            axs[row, column].set_title(f\"Feature {i}\")\n",
    "            axs[row,column].plot(x_values, y_values_pos.pdf(x_values), 'g-')\n",
    "            axs[row,column].plot(x_values, y_values_neg.pdf(x_values), 'r-')\n",
    "\n",
    "            \n",
    "        if plot=='scatter':\n",
    "            axs[row, column].plot(negs, 'r.')\n",
    "            axs[row, column].plot(post, 'g.')\n",
    "            axs[row, column].set_title(f\"Feature {i}\")\n",
    "            axs[row, column].set_xticklabels([])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
